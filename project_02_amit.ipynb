{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ed8bfa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "### Amit Kumar Singh Yadav ##\n",
    "#############################\n",
    "# Project 2: Vector Quantization and Discrete Cosine Transform\n",
    "# Part 1 - Vector Quantization\n",
    "\n",
    "\"\"\"Write a program to implement vector quantization on a gray-scale image using a \"vector\"\n",
    "that consists of a 4x4 block of pixels. Design your codebook using all the blocks in the image\n",
    "as training data, using the Generalized Lloyd algorithm. Then quantize the image using your codebook.\n",
    "Explore the impact of different codebook sizes,for example, L=128 and L=256. \n",
    "Next, train your codebook on a collection of 10 images, and quantize your original image using the new codebook.\n",
    "Compare your results on the new codebook to your previous results, and explain any differences\n",
    "\n",
    "Need to test method on at least two different images.\n",
    "\"\"\"\n",
    "\n",
    "###############################\n",
    "### Importing the packages ####\n",
    "###############################\n",
    "import numpy as np\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import lbg\n",
    "import cv2\n",
    "\n",
    "###############################\n",
    "### Defining Helper functions #\n",
    "###############################\n",
    "\n",
    "#########################################################################      \n",
    "# helper function to get MSE\n",
    "#########################################################################\n",
    "def getMSE(input1,input2):\n",
    "    return(np.sum((np.array(input1) - np.array(input2))**2))\n",
    "\n",
    "#########################################################################\n",
    "# function to calculate PSNR between two images\n",
    "# taken as it is from Project #1\n",
    "#########################################################################\n",
    "def getPSNR(targetImg:np.ndarray, predictedImg:np.ndarray) -> float:\n",
    "        # Mean Square Error zero means no noise\n",
    "        # hence PSNR will explode\n",
    "        # PSRN is not good measure for identical images\n",
    "        mean_square_error = np.mean((predictedImg - targetImg) ** 2)\n",
    "        if(mean_square_error == 0):\n",
    "            print(\"images are identical\")\n",
    "            return 100.0 # for simplicity\n",
    "        # note it is in db\n",
    "        return 20 * math.log10(255.0 / math.sqrt(mean_square_error))\n",
    "\n",
    "#######################################################################    \n",
    "# helper function to find error of a vector from all the training data\n",
    "#######################################################################\n",
    "def getError(vector, training_data):\n",
    "    return np.sum( (np.array(vector)-np.array(training_data)) **2/ len(training_data))\n",
    "\n",
    "#########################################################################\n",
    "# function to prepocess each image \n",
    "# convert to grayscale and then resize it to 512 x 512 by default\n",
    "#########################################################################   \n",
    "def preprocess(img_to_compress_path, all_images_path, size = (512,512)):\n",
    "    # read the image in grayscale\n",
    "    img_to_compress = cv2.imread(img_to_compress_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # we will resize th image to 512 x 512\n",
    "    # let's resize\n",
    "    img_to_compress = cv2.resize(img_to_compress,size, interpolation = cv2.INTER_AREA)\n",
    "    # let's save it as orginal image to quantize to PSNR calculation\n",
    "    cv2.imwrite(\"original_grayscale.png\",img_to_compress)\n",
    "    \n",
    "    all_images_list = [] #to store grey-scale imgs\n",
    "    for path in all_images_path:\n",
    "        tmp = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        all_images_list.append(cv2.resize(tmp,size, interpolation = cv2.INTER_AREA))\n",
    "    return img_to_compress, all_images_list\n",
    "\n",
    "   \n",
    "###########################################################################\n",
    "# helper function to extract vectors from give set of images by default 4x4\n",
    "###########################################################################\n",
    "def GetVector(train_resized_img_list, size=(4,4)):\n",
    "    train_vec = []\n",
    "    for train_img in train_resized_img_list:\n",
    "        for i in range(0, train_img.shape[0], size[0]):\n",
    "            for j in range(0, train_img.shape[1], size[1]):\n",
    "                train_vec.append(train_img[i:i+size[0], j:j+size[1]].reshape((size[0]*size[1])))\n",
    "    train_vec = np.array(train_vec)\n",
    "    return train_vec\n",
    "\n",
    "#########################################################################\n",
    "# helper function to find Nearest point when encoding\n",
    "#########################################################################\n",
    "def getNearestCode(point_2_encode, codebook):\n",
    "    tmp_code = np.zeros((codebook.shape[0],))\n",
    "    for i in range(0, codebook.shape[0]):\n",
    "        tmp_code[i] = np.mean((np.subtract(point_2_encode,codebook[i])**2))\n",
    "    return np.argmin(tmp_code,axis=0)\n",
    "\n",
    "\n",
    "###########################################################################\n",
    "# helper function to create codebook from given vectors\n",
    "###########################################################################\n",
    "def GetCodebook(train_vec,codebook_size):\n",
    "    # initial codebook\n",
    "    codebook = []\n",
    "    initial_code = []\n",
    "    # let's get mean 16-dimensional vector \n",
    "    # this can be the best codebook of size 1 :>\n",
    "    \n",
    "    mean_vec = train_vec / len(train_vec)\n",
    "    # # sum of all the mean vectors \n",
    "    sum_vec = np.sum(mean_vec, axis=0)\n",
    "    # intial code will be \n",
    "    initial_code = sum_vec.tolist()\n",
    "    codebook.append(initial_code)\n",
    "    # get error\n",
    "    error = getError(initial_code,train_vec)\n",
    "    # generate codebook of given size\n",
    "    # now we can keep updating codebook by adding more and more codes in it\n",
    "    # unless the size is equal to given codebook_size\n",
    "    while len(codebook) < codebook_size:\n",
    "        codebook = extendCodebook(train_vec,codebook, 0.05, error)\n",
    "    return np.array(codebook)\n",
    "           \n",
    "#####################################################################\n",
    "# helper function to extend the codebook\n",
    "#####################################################################\n",
    "def extendCodebook(training_vec, start_codebook,threshold,initial_error):\n",
    "    # training_vec\n",
    "    # start_codebook\n",
    "    # threshold \n",
    "    # initial_error\n",
    "    \n",
    "    # let's define empty extended code book\n",
    "    extended_codebook =[]\n",
    "    for code in start_codebook: \n",
    "        extended_codebook.extend(((np.array(code) * (1.0 + threshold)).tolist(),\n",
    "                                  (np.array(code) * (1.0 - threshold)).tolist()))\n",
    "\n",
    "    # k-means using LBG\n",
    "    avg_error = 0\n",
    "    \n",
    "    # any value higher than initial threshold is good\n",
    "    error = threshold + 1 \n",
    "    itern = 0\n",
    "    while error > threshold:\n",
    "        # loop unless means/centroid are within a limit\n",
    "        \n",
    "        # let's intialize a nearest neighbour for all the training examples\n",
    "        nearest_vec = [None] * len(training_vec) \n",
    "        # this will be a dictionary that maps each training vec to a code in codebook \n",
    "        dict_vec = defaultdict(list) #a dictionary to map vec to codebook values\n",
    "        # this dicitonary will just map indices\n",
    "        dict_id = defaultdict(list) #map ideces\n",
    "        # for each training vector\n",
    "        for train_indx,train_v in enumerate(training_vec):\n",
    "            # initialized initial minimum error as None\n",
    "            min_error = None\n",
    "            # nearest_code_id is set to None, we don't know yet\n",
    "            nearest_code_id = None\n",
    "            # now for current extended codebook, we need to find error of each of the training vector\n",
    "            # from it\n",
    "            \n",
    "            for codebook_indx,codebook_code in enumerate(extended_codebook):\n",
    "                # get MSE error for training vec from each code iteratively\n",
    "                current_error = getMSE(train_v,codebook_code)\n",
    "                # save code with minimum error \n",
    "                if min_error is None or current_error < min_error:\n",
    "                    min_error = current_error\n",
    "                    nearest_vec[train_indx] = codebook_code\n",
    "                    nearest_code_id = codebook_indx\n",
    "            # at end of it, for given training vector we have nearest code indx and code value\n",
    "            # save it in the dictionary\n",
    "            dict_vec[nearest_code_id].append(train_v)\n",
    "            dict_id[nearest_code_id].append(train_indx)\n",
    "\n",
    "        # Now we have got clusteres\n",
    "        # let update codebook\n",
    "        for code_indx in range(len(extended_codebook)):\n",
    "            # all training vectors in current code_indx cluster\n",
    "            train_vecs = dict_vec.get(code_indx) or []\n",
    "            num_vecs = len(train_vecs)\n",
    "            if num_vecs > 0:\n",
    "                # let's find new mean/center\n",
    "                \n",
    "                tmp_sum = np.sum(np.array(train_vecs)/len(train_vecs), axis = 0)\n",
    "                new_mean = tmp_sum.tolist()\n",
    "                \n",
    "                # save the updated code in the extended_codebook\n",
    "                extended_codebook[code_indx] = new_mean\n",
    "                # update nearest for all the training examples\n",
    "                for indx in dict_id[code_indx]:\n",
    "                    nearest_vec[indx] = new_mean\n",
    "\n",
    "        # re-calculate error\n",
    "        prev_error = avg_error if avg_error > 0 else initial_error\n",
    "        avg_error = getError(nearest_vec,training_vec)\n",
    "        error = (prev_error - avg_error) / prev_error\n",
    "\n",
    "    return extended_codebook\n",
    "            \n",
    "                \n",
    "\n",
    "#########################################################################\n",
    "# Helper function to VQ Encode an image \n",
    "#########################################################################\n",
    "def VQEncoder(img_2_encode, codebook, size=(4,4)):\n",
    "    # encoded img \n",
    "    # loop and find index of nearest code\n",
    "    encoded_img = np.zeros((img_2_encode.shape[0] // size[0], img_2_encode.shape[1] // size[1]))\n",
    "    row = 0\n",
    "    for i in range(0,img_2_encode.shape[0],size[0]):\n",
    "        col = 0\n",
    "        for j in range(0,img_2_encode.shape[1],size[1]):\n",
    "            vector_2_encode = img_2_encode[i:i+4,j:j+4].reshape((size[0]*size[1])).copy()\n",
    "            encoded_img[row,col] = getNearestCode(vector_2_encode,codebook)\n",
    "            col += 1\n",
    "        row += 1\n",
    "    return encoded_img\n",
    "            \n",
    "#########################################################################\n",
    "# Helper function to VQ Decode an image\n",
    "#########################################################################\n",
    "def VQDecoder(compressed_img, codebook, size=(4,4)):\n",
    "    decoded_img = np.zeros((compressed_img.shape[0] * size[0], compressed_img.shape[1] * size[1]))\n",
    "    row = 0\n",
    "    for i in range(0,compressed_img.shape[0]):\n",
    "        col = 0\n",
    "        for j in range(0, compressed_img.shape[1]):\n",
    "            decoded_img[row:row+size[0],col:col+size[1]] = codebook[int(compressed_img[i,j])].reshape((size[0],size[1]))\n",
    "            col += size[1]\n",
    "        row += size[0]\n",
    "    return decoded_img\n",
    "\n",
    "    \n",
    "########################################################################\n",
    "# code to preprocess all the images, extract 4x4 training data from \n",
    "# all the images\n",
    "# create codebook using it\n",
    "# compress using the codebook\n",
    "# decompress using the codebook\n",
    "# getPSNR value for evaluating quality of reconstructed image\n",
    "########################################################################\n",
    "def VectorQuantization(img_to_compress_path, all_images_path, codebook_size)->bool:\n",
    "    img_to_compress, all_train_img  = preprocess(img_to_compress_path,all_images_path)\n",
    "    num_of_train_img = len(all_images_path) \n",
    "    # let's generate vector from all the training images\n",
    "    training_vec = GetVector(all_train_img)\n",
    "    # using these training vectors, let's generate the code book\n",
    "    print('wait: creating codebook!')\n",
    "#     codebook = lbg.generate_codebook(training_vec, codebook_size)\n",
    "# the generate codebook package was downloaded from here, it works good for 2-D data but \n",
    "# is very slow of more than two dimensional data.\n",
    "    codebook = GetCodebook(training_vec, codebook_size)\n",
    "    # we have the codebook, now let's encode the given image\n",
    "    print('compressing/encdoing the given image')\n",
    "    encoded_img = VQEncoder(img_to_compress, codebook)\n",
    "    print('decoding')\n",
    "    decoded_img = VQDecoder(encoded_img, codebook)\n",
    "    cv2.imwrite(\"recons_with_s_\" + str(codebook_size) + \"train_s_\" + str(num_of_train_img)+\".png\",decoded_img)\n",
    "    print(\"PSNR of Quantized Reconstructed Image w.r.t Original Image at Size=\", codebook_size, \": \", getPSNR(img_to_compress,decoded_img))\n",
    "    return True\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0b34a9fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wait: creating codebook!\n",
      "compressing/encdoing the given image\n",
      "decoding\n",
      "PSNR of Quantized Reconstructed Image w.r.t Original Image at Size= 32 :  22.97466333306286\n",
      "wait: creating codebook!\n",
      "compressing/encdoing the given image\n",
      "decoding\n",
      "PSNR of Quantized Reconstructed Image w.r.t Original Image at Size= 64 :  23.691524497967173\n",
      "wait: creating codebook!\n",
      "compressing/encdoing the given image\n",
      "decoding\n",
      "PSNR of Quantized Reconstructed Image w.r.t Original Image at Size= 128 :  24.048097321036725\n",
      "wait: creating codebook!\n",
      "compressing/encdoing the given image\n",
      "decoding\n",
      "PSNR of Quantized Reconstructed Image w.r.t Original Image at Size= 256 :  24.373858565347177\n"
     ]
    }
   ],
   "source": [
    "codebook_size_list = [32, 64,128,256]\n",
    "\n",
    "img_to_compress_path = 'barbara.png'\n",
    "# same_image_list = ['barbara.png'] \n",
    "# for codebook_size in codebook_size_list:\n",
    "#     run_success = VectorQuantization(img_to_compress_path, same_image_list, codebook_size)\n",
    "    \n",
    "    \n",
    "different_10_img_list = [\n",
    "    'pool.png', 'tulips.png', 'watch.png','mountain.png', 'zelda.png', \n",
    "    'arctichare.png','baboon.png', 'monarch.png', 'cat.png', 'airplane.png']\n",
    "\n",
    "for codebook_size in codebook_size_list:\n",
    "    run_success = VectorQuantization(img_to_compress_path, different_10_img_list, codebook_size)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc15be6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################\n",
    "### Amit Kumar Singh Yadav ##\n",
    "#############################\n",
    "# Project 2: Vector Quantization and Discrete Cosine Transform\n",
    "# Part 2 - Discrete Cosine Transform\n",
    "\n",
    "\"\"\"\n",
    "Write a program that examines the effect of approximating an image with a partial set of DCT coefficients.\n",
    "Using an 8Ã—8 DCT, reconstruct the image with K<64 coefficients, when K=2,4,8,16, and 32. \n",
    "How many coefficients are necessary to provide a \"satisfactory\" reconstruction?\n",
    "Define how you characterize \"satisfactory\" reconstruction.\n",
    "Need to test method on at least two different images.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#############################\n",
    "### Helper functions ##\n",
    "#############################\n",
    "import math\n",
    "import numpy as np\n",
    "from numpy import *\n",
    "import cv2 # for reading/writing the image\n",
    "\n",
    "##########################################################\n",
    "# function to get DCT Matrix\n",
    "##########################################################\n",
    "def getDCTMatrix(size=(8,8)):\n",
    "    # create empty dct matrix \n",
    "    # we will fill it\n",
    "    matrix = np.zeros(size)\n",
    "    # let's fill element inside the DCT matrix\n",
    "    # value for u = 0\n",
    "    for i in range(size[0]):\n",
    "        matrix[0,i] = sqrt(2.0/8) / sqrt(2.0)\n",
    "    # value for remaining elements i.e. u!=0\n",
    "    for u in range(1,size[0]):\n",
    "        for v in range(size[1]):\n",
    "            matrix[u,v] = sqrt(2.0/8) * cos((pi/8) * u * (v + 0.5))\n",
    "    return matrix\n",
    "\n",
    "##########################################################    \n",
    "# helper function to calculateDCT\n",
    "# input will be block of image (8x8)\n",
    "# and matrix for getting DCT\n",
    "##########################################################\n",
    "def calculateDCT(block,matrix):\n",
    "    return np.dot(np.dot(matrix,block),matrix.transpose())\n",
    "\n",
    "##########################################################\n",
    "# helper function to calculateInvDCT\n",
    "# input will be block of image (8x8)\n",
    "# and matrix for getting IDCT, i.e., transpose(DCT)\n",
    "##########################################################\n",
    "def calculateInvDCT(block,matrix):\n",
    "    # we know that InvDCT = transpose of DCT\n",
    "    return np.dot(np.dot(matrix.transpose(),block),matrix)\n",
    "\n",
    "##########################################################\n",
    "# helper function to reconstruct the image using K elements\n",
    "# input will be K, full_dct_block\n",
    "##########################################################\n",
    "# this code is made with help from \n",
    "# https://github.com/tesfagabir/Digital-Image-Processing/blob/master/10-Implementing-JPEG-Data-Compression-in-Python.ipynb\n",
    "# there can be an optimized version of it\n",
    "def getFirstKCoef(full_dct_block,K):\n",
    "    full_dct_block = np.array(full_dct_block)\n",
    "    # size of first_k_dct_block will be \n",
    "    # same but some values will be zero\n",
    "    first_k_dct_block = np.zeros(full_dct_block.shape)\n",
    "    \n",
    "    # we will go in zigzag order in order to get first K coefficients\n",
    "    (i,j) = (0,0)\n",
    "    # initial start direction \n",
    "    direction = 'right'\n",
    "    \n",
    "    # in total there are 64 coeffiecient, we need first K from them\n",
    "    for k in range(K):\n",
    "        first_k_dct_block[i][j] = full_dct_block[i][j]\n",
    "        # if next step is to go in right just increase j \n",
    "        if direction == 'right':\n",
    "            j += 1\n",
    "            # if it's last row elements, we can't go down, just go up right\n",
    "            if i == full_dct_block.shape[0] - 1:\n",
    "                direction = 'up_right'\n",
    "            else:\n",
    "                # else keep going down left\n",
    "                direction = 'down_left'\n",
    "         # if last step was down_left then take that value\n",
    "        elif direction == 'down_left':\n",
    "            i += 1\n",
    "            j -= 1\n",
    "            # if it's last row element go to right element\n",
    "            if i == full_dct_block.shape[0] - 1:\n",
    "                direction = 'right'\n",
    "            elif j == 0:\n",
    "                # else keep going down\n",
    "                direction = 'down'\n",
    "        # if it was from down then either go up right if it's first column\n",
    "        # otherwise go down_left\n",
    "        elif direction == 'down':\n",
    "            i += 1\n",
    "            if j == 0:\n",
    "                direction = 'up_right'\n",
    "            else:\n",
    "                direction = 'down_left'\n",
    "        # if last step was up_right and u reach last column then just go down\n",
    "        # else go right\n",
    "        elif direction == 'up_right':\n",
    "            i -= 1\n",
    "            j += 1\n",
    "            if j == full_dct_block.shape[1] - 1:\n",
    "                direction = 'down'\n",
    "            elif i == 0:\n",
    "                direction = 'right'\n",
    "\n",
    "    return first_k_dct_block\n",
    "        \n",
    "\n",
    "# function to calculate PSNR between two images\n",
    "# taken as it is from Project #1\n",
    "def getPSNR(targetImg:np.ndarray, predictedImg:np.ndarray) -> float:\n",
    "        # Mean Square Error zero means no noise\n",
    "        # hence PSNR will explode\n",
    "        # PSRN is not good measure for identical images\n",
    "        mean_square_error = np.mean((predictedImg - targetImg) ** 2)\n",
    "        if(mean_square_error == 0):\n",
    "            print(\"images are identical\")\n",
    "            return 100.0 # for simplicity\n",
    "        # note it is in db\n",
    "        return 20 * math.log10(255.0 / math.sqrt(mean_square_error))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96dfe951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PSNR of Reconstructed Image w.r.t Original Image at K: 2 =  23.104735234067803\n",
      "PSNR of Quantized Reconstructed Image w.r.t Original Image at K: 2 =  23.09814919994263\n",
      "PSNR of Reconstructed Image w.r.t Original Image at K: 4 =  25.267811658539397\n",
      "PSNR of Quantized Reconstructed Image w.r.t Original Image at K: 4 =  25.247560977066094\n",
      "PSNR of Reconstructed Image w.r.t Original Image at K: 8 =  28.16735839920744\n",
      "PSNR of Quantized Reconstructed Image w.r.t Original Image at K: 8 =  28.092216566580706\n",
      "PSNR of Reconstructed Image w.r.t Original Image at K: 16 =  31.465280191747603\n",
      "PSNR of Quantized Reconstructed Image w.r.t Original Image at K: 16 =  31.029886100428904\n",
      "PSNR of Reconstructed Image w.r.t Original Image at K: 32 =  36.56856620282969\n",
      "PSNR of Quantized Reconstructed Image w.r.t Original Image at K: 32 =  33.27543315813593\n"
     ]
    }
   ],
   "source": [
    "########################################\n",
    "########## Initialization ##############\n",
    "########################################\n",
    "K_list = [2,4,8,16,32]\n",
    "for K in K_list:\n",
    "    resize_dim = (512,512)\n",
    "    img_path = \"./boat.png\"\n",
    "\n",
    "    ########################################\n",
    "    ########## Read Image and Resize #######\n",
    "    ########################################\n",
    "    img = cv2.imread(img_path,cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img,resize_dim, interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    ###################################\n",
    "    ########## Apply DCT ##############\n",
    "    ###################################\n",
    "    h, w = [512,512]\n",
    "    size=(8,8) # block size\n",
    "    dct_img = np.zeros((h,w))\n",
    "    recon_img = np.zeros((h,w))\n",
    "    dct_img_till_k = np.zeros((h,w))\n",
    "    dct_block = getDCTMatrix(size)\n",
    "    # take dct of image and make another image keeping only first K coefficients\n",
    "    # Encoder gives dct_img_till_k  (to compress it remove some DCT)\n",
    "    for i in range(0,h,size[0]):\n",
    "        for j in range(0,w,size[1]):\n",
    "            # extract block of give size and do DCT on it\n",
    "            img_block = img[i:i+size[0], j:j+size[1]]\n",
    "            dct_img_block = calculateDCT(img_block,dct_block)\n",
    "            # copy to main image\n",
    "            dct_img[i:i+size[0],j:j+size[1]] = np.copy(dct_img_block)\n",
    "            dct_img_till_k[i:i+size[0],j:j+size[1]] = getFirstKCoef(dct_img_block,K)\n",
    "\n",
    "    #inverse dct for each 8x8 block\n",
    "    for i in range(0,h,size[0]):\n",
    "        for j in range(0,w,size[1]):\n",
    "            img_block = dct_img_till_k[i:i+size[0], j:j+size[1]]\n",
    "            recon_blk = calculateInvDCT(img_block,dct_block)\n",
    "            recon_img[i:i+size[0],j:j+size[1]] = np.copy(recon_blk)\n",
    "\n",
    "\n",
    "    #save reconstructed image\n",
    "    cv2.imwrite(\"recons_img_with_K_\" + str(K) + \".png\",recon_img)\n",
    "    #calculate psnr\n",
    "    psnr_val = getPSNR(img,recon_img)\n",
    "    print(\"PSNR of Reconstructed Image w.r.t Original Image at K:\", K, \"= \", psnr_val)\n",
    "\n",
    "    # Now let's see what happens if we even quantize the image\n",
    "    quantized_img = np.zeros((512,512))\n",
    "    quantized_dct_img = np.zeros((512,512))\n",
    "    dequantized_dct_img = np.zeros((512,512))\n",
    "    dequantized_dct_img_till_k = np.zeros((512,512))\n",
    "    quantized_recons_img = np.zeros((512,512))\n",
    "\n",
    "    # quantization coeeficients from 8x8 DCT block from Lecture Slide\n",
    "    quantization_coeff = [\n",
    "            [16, 11, 10, 16, 24, 40, 51, 61],\n",
    "            [12, 12, 14, 19, 26, 58, 60, 55],\n",
    "            [14, 13, 16, 24, 40, 57, 69, 56],\n",
    "            [14, 17, 22, 29, 51, 87, 80, 62],\n",
    "            [18, 22, 37, 56, 68, 109, 103, 77],\n",
    "            [24, 35, 55, 64, 81, 104, 113, 92],\n",
    "            [49, 64, 78, 87, 103, 121, 120, 101],\n",
    "            [72, 92, 95, 98, 112, 100, 103, 99]\n",
    "                        ]\n",
    "\n",
    "    # step will be: first convert img to dct -> quantize the DCT\n",
    "    # dequantized the DCT image -> do IDCT -> get image\n",
    "\n",
    "    # we have DCT block and dct_img from previous step, just do quantization\n",
    "    for i in range(0,h,size[0]):\n",
    "        for j in range(0,w,size[1]):\n",
    "            quantized_dct_img[i:i+size[0],j:j+size[1]] = np.around(np.divide(dct_img[i:i+size[0],j:j+size[1]],quantization_coeff))\n",
    "\n",
    "    # for code simplicity, we will not get first K from it after quantization\n",
    "    # we will just dequantize and then take the first K\n",
    "    # this help us to short the code\n",
    "    # but not it is not pragmatic\n",
    "    # as image changed to DCT -> extract first K and then quantize is optimal case\n",
    "\n",
    "\n",
    "    # let's do de-quantization\n",
    "    for i in range(0,h,size[0]):\n",
    "        for j in range(0,w,size[1]):\n",
    "            dequantized_dct_img[i:i+size[0],j:j+size[1]] = np.around(np.multiply(quantized_dct_img[i:i+size[0],j:j+size[1]],quantization_coeff))\n",
    "\n",
    "    # now we have dequantized the whole image, let's get the first K DCT coefficients\n",
    "    for i in range(0,h,size[0]):\n",
    "        for j in range(0,w,size[1]):\n",
    "            dct_img_block = dequantized_dct_img[i:i+8, j:j+8]\n",
    "            dequantized_dct_img_till_k[i:i+size[0],j:j+size[1]] = getFirstKCoef(dct_img_block,K)\n",
    "\n",
    "    # now inverse DCT to get quantized_recons_img\n",
    "    #inverse dct for each 8x8 block\n",
    "    for i in range(0,h,size[0]):\n",
    "        for j in range(0,w,size[1]):\n",
    "            img_block = dequantized_dct_img_till_k[i:i+size[0], j:j+size[1]]\n",
    "            recon_blk = calculateInvDCT(img_block,dct_block)\n",
    "            quantized_recons_img[i:i+size[0],j:j+size[1]] = np.copy(recon_blk)\n",
    "\n",
    "\n",
    "    #save reconstructed image\n",
    "    cv2.imwrite(\"quantized_recons_img_with_K_\" + str(K) + \".png\",quantized_recons_img)\n",
    "    #calculate psnr\n",
    "    psnr_val = getPSNR(img,quantized_recons_img)\n",
    "    print(\"PSNR of Quantized Reconstructed Image w.r.t Original Image at K:\", K, \"= \", psnr_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f109026b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('ece661')",
   "language": "python",
   "name": "python3813jvsc74a57bd0e704f999e38f1014731e71e7981b69c7b1dc94fcef1e2bd020f2333129e3242b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
